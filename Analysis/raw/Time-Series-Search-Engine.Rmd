---
title: "Time Series Analysis"
author: "Eldhose Poulose"
date: "24.04.2021"
output:
  pdf_document: 
    latex_engine: xelatex
  html_document: default
subtitle: Apple Mobility Trends Data
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Introduction

Through this [RMarkdown](www.rstudio.com) I want to create a deep understanding of the usage of R packages, and deepen my data analysis and visualisation skills.

Create an R Notebook which is then used as a Portfolio when applying for Data Science positions.

## Steps

* Ingest Data
  + [Apple Mobility Trends Data](https://covid19.apple.com/mobility)
* Merge datasets
* Exploratory Data Analysis and Visualizations
* Time Series Analysis and Forecasts
* Do “out of the box” time series forecast.
* Analyze fluctuations around time series trends.

**Remark:** The time series section is done for illustration purposes only. The forecasts there should not be taken seriously.

## Motivation

## Overall Process

# Dataset

### Apple Mobility Trends Data
* Download the data
The [Apple's page ](https://covid19.apple.com/mobility) provides the Dataset for this data analysis.
* Import the data and summarize it
* Transform the data into long form
* Partition the data into subsets that correspond to combinations of geographical regions and transportation types
* Make contingency matrices and corresponding heat-map plots
* Make NN graphs over the contingency matrices and plot communities
* Plot the corresponding Time Series


```{r pkg loader, include=FALSE}
#tinytex::install_tinytex()
#install.packages("devtools") 
#install.packages("webshot")
#webshot::install_phantomjs()
#devtools::install_github("rstudio/d3heatmap")
#install.packages("XML", repos = "http://www.omegahat.org/R")
#install.packages("RTidyHTML", repos = "http://www.omegahat.org/R", type="source")
ipak <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg)) 
        install.packages(new.pkg, dependencies = TRUE)
    sapply(pkg, require, character.only = TRUE)
}

packages <- c("ggplot2", "ggfortify", "FactoMineR", "statsr","devtools", "MASS","graphics","rbokeh","flexdashboard","NLP","tidyverse","reshape2","plyr","tinytex","Matrix","gridExtra","d3heatmap","igraph","zoo","purrr","rvest","httr","dplyr", "magrittr","stringr","RSelenium","janitor","curl","tidyr","forecast")
ipak(packages)
```


### Ingest Data


```{r}
get_apple_target <- function(cdn_url = "https://covid19-static.cdn-apple.com",
                             json_file = "covid19-mobility-data/current/v3/index.json") {
  tf <- tempfile(fileext = ".json")
  curl::curl_download(paste0(cdn_url, "/", json_file), tf)
  json_data <- jsonlite::fromJSON(tf)
  paste0(cdn_url, json_data$basePath, json_data$regions$`en-us`$csvPath)
}
get_apple_target()
```
```{r}
# get_apple_data <- function(url = get_apple_target(),
#                              fname = "applemobilitytrends-",
#                              date = stringr::str_extract(get_apple_target(), "\\d{4}-\\d{2}-\\d{2}"),
#                              ext = "csv",
#                              dest = "/Users/pouloeld/Documents/R_Projects/Time-Series-Analysis/AppleMobilityTrends/data",
#                              save_file = c("n", "y")) {
# 
#   save_file <- match.arg(save_file)
#   message("target: ", url)
# 
#   destination <- paste0(dest,"/",fname,date,".csv")
# 
#   tf <- tempfile(fileext = ext)
#   curl::curl_download(url, tf)
# 
#   ## We don't save the file by default
#   switch(save_file,
#          y = fs::file_copy(tf, destination),
#          n = NULL)
# 
#   read.csv(tf)
# }
```

```{r}
#appleMobility <- get_apple_data()
```

```{r}
fileName <- paste0("applemobilitytrends-",as.String(Sys.Date()-1),".csv")
# setwd("~/Documents/R_Projects/Time-Series-Analysis/AppleMobilityTrends")
# url <- paste0("https://covid19-static.cdn-apple.com/covid19-mobility-data/2106HotfixDev20/v3/en-us/applemobilitytrends-",as.String(Sys.Date()-1),".csv")
download.file(get_apple_target(),fileName)
appleMobility <- read.csv(fileName)
```
**Observation:** Reference date for normalization is January 13, 2020. Note the values in that column are set to 100.

**Data Dimension**
```{r}
dim(appleMobility)
```

```{r}
summary(as.data.frame(unclass(appleMobility[,1:3]), stringsAsFactors = TRUE))
```



**Answering basic questions about the Dataset**

* Here I try to answer the basic questions which I come across from the data.
  + How many geo_types are present in the data?
  + How many unique regions are present in the data?
  + How many transportation modes are present in the data?
  + How many Countries are present in the data? **Note:** Big countries are divides into regions are provided them in the regions column. 
  
```{r}
lsGeo_type <- as.String(levels(appleMobility$geo_type))
lsGeo_type
```


```{r}
print(length(levels(appleMobility$region)))
#lsRegion <- as.String(levels(appleMobility$region))
#lsRegion
```


```{r}
print(as.String(levels(appleMobility$transportation_type)))
```

```{r}
print(length(levels(appleMobility$country)))
#print(as.String(levels(appleMobility$country)))
```
## Data transformation

Here I convert the data into narrow/long format. For this I use melt function from reshape2 package.



```{r}
#appleMobility_melted <- melt(appleMobility,id=c("geo_type","region","transportation_type","alternative_name","sub.region","country"))
colNames <- c("geo_type","region","transportation_type","alternative_name","sub.region","country")
appleMobility_melted <- tidyr::pivot_longer( data = appleMobility, cols = setdiff( names(appleMobility), colNames), names_to = "Date", values_to = "value" )
```

**Remove empty rows**
```{r}
appleMobility_na <- appleMobility_melted[complete.cases(appleMobility_melted), ]
```

```{r}
#colnames(appleMobility_na)[colnames(appleMobility_na) == "variable"] <- "Date"
```
**Clean Date Format**
```{r}
appleMobility_na$Date <- gsub("[a-zA-Z ]", "", appleMobility_na$Date)
```

**Add: DateInfo, Day**

```{r}
appleMobility_na$Date <- as.POSIXct(appleMobility_na$Date, format = "%Y.%m.%d", origin = "1970.01.01" )
#unique(appleMobility_na$Date) #To see the days
appleMobility_na$Day <- weekdays(appleMobility_na$Date)
appleMobility_na$Day <- as.factor(appleMobility_na$Day)
appleMobility_na$DateInfo <- format(appleMobility_na$Date, "%a %b %d %Y")
appleMobility_na$DateInfo <- as.factor(appleMobility_na$DateInfo)
```

**Draw Random Samples**
```{r radnomSample}
set.seed(123)
appleMobility_na %>% dplyr::sample_n(10)
```
##Summary of the cleaned data
```{r}
summary(as.data.frame(unclass(appleMobility_na), stringsAsFactors = TRUE))
```

## Data Partition

*I am interested in the geographical types and transportation modes. Therefore we group the data as per this requirement.

```{r}
appleMobility_na %>%
  dplyr::group_by(geo_type, transportation_type) %>%
  dplyr::count()
```
```{r}
appleMobility_part <- split(appleMobility_na, appleMobility_na[,c("geo_type","transportation_type")])
```

## Heat-Map Plots

### Contigency Matrix
```{r}
aMatDateRegion <- purrr::map(appleMobility_part, function(dfX) { xtabs( formula = value ~ Date + region, data = dfX, sparse = TRUE ) } )
aMatDateRegion <- aMatDateRegion[ purrr::map_lgl(aMatDateRegion, function(x) nrow(x) > 0 ) ]

```

```{r}
sparseMatDateRegion <- purrr::map_df(aMatDateRegion, Matrix::summary, .id = "Type" )
head(sparseMatDateRegion)
```



```{r}
ggplot2::ggplot(sparseMatDateRegion) +
  ggplot2::geom_tile( ggplot2::aes( x = j, y = i, fill = log10(x)), color = "white") +
  ggplot2::scale_fill_gradient(low = "white", high = "blue") +
  ggplot2::xlab("Region") + ggplot2::ylab("Date") + 
  ggplot2::facet_wrap( ~Type, scales = "free", ncol = 2)
```

```{r}
# d3heatmap::d3heatmap( x = aMatDateRegion[["country/region.driving"]], Rowv = FALSE )

```


```{r}
# th <- 0.94
# aNNGraphs <-
#   purrr::map( aMatDateRegion, function(m) {
#     m2 <- cor(as.matrix(m))
#     for( i in 1:nrow(m2) ) {
#       m2[i,i] <- 0
#     }
#     m2 <- as( m2, "dgCMatrix")
#     #m2@x[ m2@x <= th ] <- 0
#     m2@x[ m2@x > th ] <- 1
#     igraph::graph_from_adjacency_matrix(Matrix::drop0(m2), weighted = TRUE, mode = "undirected")
#   })
```

```{r}
# ind <- 3
# ceb <- cluster_edge_betweenness(aNNGraphs[[ind]])
# dendPlot(ceb, mode="hclust", main = names(aNNGraphs)[[ind]])
```

```{r}
# plot(ceb, aNNGraphs[[ind]], vertex.size=1, vertex.label=NA, main = names(aNNGraphs)[[ind]])
```

# Time Series Analysis
```{r}
aDateStringToDateInfo <- unique(appleMobility_na[, c("Date", "DateInfo")] )
aDateStringToDateInfo <- setNames( aDateStringToDateInfo$DateInfo, aDateStringToDateInfo$Date )
aDateStringToDateInfo <- as.POSIXct(aDateStringToDateInfo, format = "%a %b %d %Y")
aTSDirReqByCountry <-  purrr::map( aMatDateRegion, function(m) rowSums(m) )
```


```{r}
matTS <- do.call( cbind, aTSDirReqByCountry)
```


```{r}
zooObj <- zoo::zoo( x = matTS, as.POSIXct(rownames(matTS)) )
```

```{r}
autoplot(zooObj) +
  aes(colour = NULL, linetype = NULL) +
    facet_grid(Series ~ ., scales = "free_y") +
  geom_vline( xintercept = aDateStringToDateInfo[weekdays(aDateStringToDateInfo) == "Sunday"], color = "orange", linetype = "dashed", size = 0.3 )
```


# Forecasting
```{r}
aTSModels <- purrr::map( names(zooObj), function(x) { forecast::auto.arima( zoo( x = zooObj[,x], order.by = index(zooObj) ) ) } )
```


```{r}
aTSModels <- purrr::map( names(zooObj), function(x) forecast::forecast( as.matrix(zooObj)[,x] ) )
names(aTSModels) <- names(zooObj)
```


```{r}
lsPlots <- purrr::map( names(aTSModels), function(x) autoplot(aTSModels[[x]]) + ylab("Volume") + ggtitle(x) )
names(lsPlots) <- names(aTSModels)
```

```{r}
do.call( gridExtra::grid.arrange, lsPlots )
```




## Packages, Repositories, Articles
