---
title: "Time Series Analysis"
author: "Eldhose Poulose"
date: "24.04.2021"
output:
  pdf_document: 
    latex_engine: xelatex
  html_document: default
subtitle: using Apple Mobility Trends Data
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Introduction

Through this [RMarkdown](www.rstudio.com) I want to present my sample work in Time Series Analysis, which I have done using the [Apple Mobility Trends Data](https://covid19.apple.com/mobility). I found pulling down this file challenging due to the fact that the URL for the CSV file changes daily. I mainly used the "rvest" package to harvest data from html pages and in python I use "beautifulSoup" package to scrape data. Eventhough I have experience in both I found this task challenging because my goal was to automate the entire process by harvesting the data from this page every day, run the job and mail the results to my E-Mail. I found that the URL for dataset is dynamic in some random way or as a function of the version (also dynamic) of the web content management system. Thus I understood that I can’t easily scrape it and just look for the URL embedded in the “Download the Data” button. After couple of days of research I found that the index.json contains the stable URL of the dataset for each day.


The reason behind selecting this data is becasuse of the importance of this data in this period of Pandemic. I want to explore the activities of the public and see how it is changing everyday.

## Steps

* Ingest Data
  + [Apple Mobility Trends Data](https://covid19.apple.com/mobility)
* Merge datasets
* Exploratory Data Analysis and Visualizations
* Time Series Analysis and Forecasts
* Do “out of the box” time series forecast.
* Analyze fluctuations around time series trends.

**Remark:** The time series section is done for illustration purposes only. The forecasts there should not be taken seriously.

## Motivation

## Overall Process

# Dataset

### Apple Mobility Trends Data
* Download the data
The [Apple's page ](https://covid19.apple.com/mobility) provides the Dataset for this data analysis.
* Import the data and summarize it
* Transform the data into long form
* Partition the data into subsets that correspond to combinations of geographical regions and transportation types
* Make contingency matrices and corresponding heat-map plots
* Make NN graphs over the contingency matrices and plot communities
* Plot the corresponding Time Series


```{r pkg loader, include=FALSE}
#tinytex::install_tinytex()
#install.packages("devtools") 
#install.packages("webshot")
#webshot::install_phantomjs()
#devtools::install_github("rstudio/d3heatmap")
#install.packages("XML", repos = "http://www.omegahat.org/R")
#install.packages("RTidyHTML", repos = "http://www.omegahat.org/R", type="source")
ipak <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg)) 
        install.packages(new.pkg, dependencies = TRUE)
    sapply(pkg, require, character.only = TRUE)
}

packages <- c("ggplot2", "ggfortify", "FactoMineR", "statsr","devtools", "MASS","graphics","rbokeh","flexdashboard","NLP","tidyverse","reshape2","plyr","tinytex","Matrix","gridExtra","d3heatmap","igraph","zoo","purrr","rvest","httr","dplyr", "magrittr","stringr","RSelenium","janitor","curl","tidyr","forecast")
ipak(packages)
```


### Ingest Data


```{r}
get_apple_target <- function(cdn_url = "https://covid19-static.cdn-apple.com",
                             json_file = "covid19-mobility-data/current/v3/index.json") {
  tf <- tempfile(fileext = ".json")
  curl::curl_download(paste0(cdn_url, "/", json_file), tf)
  json_data <- jsonlite::fromJSON(tf)
  paste0(cdn_url, json_data$basePath, json_data$regions$`en-us`$csvPath)
}
get_apple_target()
```


```{r}
fileName <- tail(unlist(strsplit(get_apple_target(),"/")), n=1) 
download.file(get_apple_target(),fileName)
appleMobility <- read.csv(fileName,stringsAsFactors = TRUE)
```
**Observation:** Reference date for normalization is January 13, 2020. Note the values in that column are set to 100.

**Data Dimension**
```{r}
dim(appleMobility)
```

```{r}
summary(as.data.frame(unclass(appleMobility[,1:3]), stringsAsFactors = TRUE))
```



**Answering basic questions about the Dataset**

* Here I try to answer the basic questions which I come across from the data.
  + How many geo_types are present in the data?
  + How many unique regions are present in the data?
  + How many transportation modes are present in the data?
  + How many Countries are present in the data? **Note:** Big countries are divides into regions are provided them in the regions column.
  
```{r}
lsGeo_type <- as.String(levels(appleMobility$geo_type))
lsGeo_type
```


```{r}
print(length(levels(appleMobility$region)))
#lsRegion <- as.String(levels(appleMobility$region))
#lsRegion
```


```{r}
print(as.String(levels(appleMobility$transportation_type)))
```

```{r}
print(length(levels(appleMobility$country)))
#print(as.String(levels(appleMobility$country)))
```
## Data transformation

Here I convert the data into narrow/long format. For this I use melt function from reshape2 package.



```{r}
#appleMobility_melted <- melt(appleMobility,id=c("geo_type","region","transportation_type","alternative_name","sub.region","country"))
colNames <- c("geo_type","region","transportation_type","alternative_name","sub.region","country")
appleMobility_melted <- tidyr::pivot_longer( data = appleMobility, cols = setdiff( names(appleMobility), colNames), names_to = "Date", values_to = "value" )
```

**Remove empty rows**
```{r}
appleMobility_na <- appleMobility_melted[complete.cases(appleMobility_melted), ]
```

**Clean Date Format**
```{r}
appleMobility_na$Date <- gsub("[a-zA-Z ]", "", appleMobility_na$Date)
```

**Add: DateInfo, Day**

```{r}
appleMobility_na$Date <- as.POSIXct(appleMobility_na$Date, format = "%Y.%m.%d", origin = "1970.01.01" )
appleMobility_na$Day <- weekdays(appleMobility_na$Date)
appleMobility_na$Day <- as.factor(appleMobility_na$Day)
appleMobility_na$DateInfo <- format(appleMobility_na$Date, "%a %b %d %Y")
appleMobility_na$DateInfo <- as.factor(appleMobility_na$DateInfo)
```

**Draw Random Samples**
```{r radnomSample}
set.seed(123)
appleMobility_na %>% dplyr::sample_n(10)
```
##Summary of the cleaned data
```{r}
summary(as.data.frame(unclass(appleMobility_na), stringsAsFactors = TRUE))
```

## Data Partition

*I am interested in the geographical types and transportation modes. Therefore we group the data as per this requirement.

```{r}
appleMobility_na %>%
  dplyr::group_by(geo_type, transportation_type) %>%
  dplyr::count()
```
```{r}
appleMobility_part <- split(appleMobility_na, appleMobility_na[,c("geo_type","transportation_type")])
```

## Heat-Map Plots

### Contigency Matrix
```{r}
aMatDateRegion <- purrr::map(appleMobility_part, function(dfX) { xtabs( formula = value ~ Date + region, data = dfX, sparse = TRUE ) } )
aMatDateRegion <- aMatDateRegion[ purrr::map_lgl(aMatDateRegion, function(x) nrow(x) > 0 ) ]

```

```{r}
sparseMatDateRegion <- purrr::map_df(aMatDateRegion, Matrix::summary, .id = "Type" )
head(sparseMatDateRegion)
```



```{r}
# ggplot2::ggplot(sparseMatDateRegion) +
#   ggplot2::geom_tile( ggplot2::aes( x = j, y = i, fill = log10(x)), color = "white") +
#   ggplot2::scale_fill_gradient(low = "white", high = "blue") +
#   ggplot2::xlab("Region") + ggplot2::ylab("Date") + 
#   ggplot2::facet_wrap( ~Type, scales = "free", ncol = 2)
```

```{r}
# d3heatmap::d3heatmap( x = aMatDateRegion[["country/region.driving"]], Rowv = FALSE )

```


```{r}
# th <- 0.94
# aNNGraphs <- 
#   purrr::map( aMatDateRegion, function(m) { 
#     m2 <- cor(as.matrix(m))
#     for( i in 1:nrow(m2) ) {
#       m2[i,i] <- 0
#     }
#     m2 <- as( m2, "dgCMatrix") 
#     #m2@x[ m2@x <= th ] <- 0
#     m2@x[ m2@x > th ] <- 1
#     igraph::graph_from_adjacency_matrix(Matrix::drop0(m2), weighted = TRUE, mode = "undirected")
#   })
```

```{r}
# ind <- 3
# ceb <- cluster_edge_betweenness(aNNGraphs[[ind]])  
# dendPlot(ceb, mode="hclust", main = names(aNNGraphs)[[ind]])
```

```{r}
# plot(ceb, aNNGraphs[[ind]], vertex.size=1, vertex.label=NA, main = names(aNNGraphs)[[ind]])
```

# Time Series Analysis
```{r}
aDateStringToDateInfo <- unique(appleMobility_na[, c("Date", "DateInfo")] )
aDateStringToDateInfo <- setNames( aDateStringToDateInfo$DateInfo, aDateStringToDateInfo$Date )
aDateStringToDateInfo <- as.POSIXct(aDateStringToDateInfo, format = "%a %b %d %Y")
aTSDirReqByCountry <-  purrr::map( aMatDateRegion, function(m) rowSums(m) )
```


```{r}
matTS <- do.call( cbind, aTSDirReqByCountry)
```


```{r}
zooObj <- zoo::zoo( x = matTS, as.POSIXct(rownames(matTS)) )
```

```{r}
autoplot(zooObj) +
  aes(colour = NULL, linetype = NULL) +
    facet_grid(Series ~ ., scales = "free_y") +
  geom_vline( xintercept = aDateStringToDateInfo[weekdays(aDateStringToDateInfo) == "Sunday"], color = "orange", linetype = "dashed", size = 0.3 )
```


# Forecasting
```{r}
aTSModels <- purrr::map( names(zooObj), function(x) { forecast::auto.arima( zoo( x = zooObj[,x], order.by = index(zooObj) ) ) } )
```


```{r}
aTSModels <- purrr::map( names(zooObj), function(x) forecast::forecast( as.matrix(zooObj)[,x] ) )
names(aTSModels) <- names(zooObj)
```


```{r}
lsPlots <- purrr::map( names(aTSModels), function(x) autoplot(aTSModels[[x]]) + ylab("Volume") + ggtitle(x) )
names(lsPlots) <- names(aTSModels)
```

```{r}
do.call( gridExtra::grid.arrange, lsPlots )
```

## Packages, Repositories, Articles
